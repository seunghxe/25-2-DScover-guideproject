{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rE1Gzrhff-UE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoxJIT8Qfp6w"
      },
      "source": [
        "#데이터셋 임포트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_Om3SCMfiD-",
        "outputId": "90c8248a-b105-4a07-c7f2-6b6a10bf32ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5Fc6jk7fxU_"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('/content/drive/MyDrive/[DScover] /25-2 Guide Project/train_preprocessed (2).csv')\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/[DScover] /25-2 Guide Project/test_preprocessed.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_XxYV6niOfn",
        "outputId": "eea11403-5451-494f-b127-fa0bd7989bcd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'building_id', 'date', 'precipitation', 'windspeed',\n",
              "       'power_consumption', 'building_type', 'total_floor_area',\n",
              "       'solar_capacity', 'hour', 'dow', 'month', 'day', 'is_weekend',\n",
              "       'cooling_ratio', 'THI', 'has_pv', 'has_ess', 'CDH', 'sin_hour',\n",
              "       'cos_hour', 'sin_date', 'cos_date', 'sin_month', 'cos_month',\n",
              "       'sin_dayofweek', 'cos_dayofweek', 'day_hour_mean', 'day_hour_std',\n",
              "       'hour_mean', 'hour_std', 'temp_above_24', 'temp_above_28',\n",
              "       'solar_exposure'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "df_train.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7xLrvdOiYeV",
        "outputId": "d61cb216-4133-430c-b118-17a70ecd5664"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 203932 entries, 0 to 203931\n",
            "Data columns (total 34 columns):\n",
            " #   Column             Non-Null Count   Dtype  \n",
            "---  ------             --------------   -----  \n",
            " 0   Unnamed: 0         203932 non-null  int64  \n",
            " 1   building_id        203932 non-null  int64  \n",
            " 2   date               203932 non-null  object \n",
            " 3   precipitation      203932 non-null  float64\n",
            " 4   windspeed          203932 non-null  float64\n",
            " 5   power_consumption  203932 non-null  float64\n",
            " 6   building_type      203932 non-null  object \n",
            " 7   total_floor_area   203932 non-null  float64\n",
            " 8   solar_capacity     203932 non-null  float64\n",
            " 9   hour               203932 non-null  int64  \n",
            " 10  dow                203932 non-null  int64  \n",
            " 11  month              203932 non-null  int64  \n",
            " 12  day                203932 non-null  int64  \n",
            " 13  is_weekend         203932 non-null  int64  \n",
            " 14  cooling_ratio      203932 non-null  float64\n",
            " 15  THI                203932 non-null  float64\n",
            " 16  has_pv             203932 non-null  int64  \n",
            " 17  has_ess            203932 non-null  int64  \n",
            " 18  CDH                203932 non-null  float64\n",
            " 19  sin_hour           203932 non-null  float64\n",
            " 20  cos_hour           203932 non-null  float64\n",
            " 21  sin_date           203932 non-null  float64\n",
            " 22  cos_date           203932 non-null  float64\n",
            " 23  sin_month          203932 non-null  float64\n",
            " 24  cos_month          203932 non-null  float64\n",
            " 25  sin_dayofweek      203932 non-null  float64\n",
            " 26  cos_dayofweek      203932 non-null  float64\n",
            " 27  day_hour_mean      203932 non-null  float64\n",
            " 28  day_hour_std       203932 non-null  float64\n",
            " 29  hour_mean          203932 non-null  float64\n",
            " 30  hour_std           203932 non-null  float64\n",
            " 31  temp_above_24      203932 non-null  float64\n",
            " 32  temp_above_28      203932 non-null  float64\n",
            " 33  solar_exposure     203932 non-null  float64\n",
            "dtypes: float64(23), int64(9), object(2)\n",
            "memory usage: 52.9+ MB\n"
          ]
        }
      ],
      "source": [
        "df_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqYQuQ6DifKZ",
        "outputId": "97daba5d-8030-46bf-ae7d-675547256427"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 16800 entries, 0 to 16799\n",
            "Data columns (total 35 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   Unnamed: 0            16800 non-null  int64  \n",
            " 1   building_id           16800 non-null  int64  \n",
            " 2   date                  16800 non-null  object \n",
            " 3   precipitation         16800 non-null  float64\n",
            " 4   windspeed             16800 non-null  float64\n",
            " 5   building_type         16800 non-null  object \n",
            " 6   total_floor_area      16800 non-null  float64\n",
            " 7   solar_capacity        16800 non-null  float64\n",
            " 8   hour                  16800 non-null  int64  \n",
            " 9   dow                   16800 non-null  int64  \n",
            " 10  month                 16800 non-null  int64  \n",
            " 11  day                   16800 non-null  int64  \n",
            " 12  is_weekend            16800 non-null  int64  \n",
            " 13  cooling_ratio         16800 non-null  float64\n",
            " 14  THI                   16800 non-null  float64\n",
            " 15  has_pv                16800 non-null  int64  \n",
            " 16  has_ess               16800 non-null  int64  \n",
            " 17  CDH                   16800 non-null  float64\n",
            " 18  sin_hour              16800 non-null  float64\n",
            " 19  cos_hour              16800 non-null  float64\n",
            " 20  sin_date              16800 non-null  float64\n",
            " 21  cos_date              16800 non-null  float64\n",
            " 22  sin_month             16800 non-null  float64\n",
            " 23  cos_month             16800 non-null  float64\n",
            " 24  sin_dayofweek         16800 non-null  float64\n",
            " 25  cos_dayofweek         16800 non-null  float64\n",
            " 26  day_hour_mean         16800 non-null  float64\n",
            " 27  day_hour_std          16800 non-null  float64\n",
            " 28  hour_mean             16800 non-null  float64\n",
            " 29  hour_std              16800 non-null  float64\n",
            " 30  temp_above_24         16800 non-null  float64\n",
            " 31  temp_above_28         16800 non-null  float64\n",
            " 32  pred_sunshine_hours   6300 non-null   float64\n",
            " 33  pred_solar_radiation  6300 non-null   float64\n",
            " 34  solar_exposure        16800 non-null  float64\n",
            "dtypes: float64(24), int64(9), object(2)\n",
            "memory usage: 4.5+ MB\n"
          ]
        }
      ],
      "source": [
        "df_test.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "yQl_A-jYhGnb",
        "outputId": "6ae28f0f-df46-4ad4-e249-0a03bc561dc3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         호텔\n",
              "1         호텔\n",
              "2         호텔\n",
              "3         호텔\n",
              "4         호텔\n",
              "          ..\n",
              "203927    호텔\n",
              "203928    호텔\n",
              "203929    호텔\n",
              "203930    호텔\n",
              "203931    호텔\n",
              "Name: building_type, Length: 203932, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>building_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>호텔</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>호텔</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>호텔</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>호텔</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>호텔</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203927</th>\n",
              "      <td>호텔</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203928</th>\n",
              "      <td>호텔</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203929</th>\n",
              "      <td>호텔</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203930</th>\n",
              "      <td>호텔</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203931</th>\n",
              "      <td>호텔</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>203932 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "df_train['building_type']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGe61Mx_hD2F"
      },
      "source": [
        "##데이터셋 추가 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGl1COfhj_7L",
        "outputId": "bf69059b-6c96-482f-d4db-b27c30865523"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before: (203932, 34) (16800, 35)\n",
            "After : (203932, 32) (16800, 31)\n"
          ]
        }
      ],
      "source": [
        "# 불필요한 컬럼 드랍\n",
        "drop_cols_train = [\"Unnamed: 0\", \"date\"]\n",
        "drop_cols_test = [\"Unnamed: 0\", \"date\", \"pred_sunshine_hours\", \"pred_solar_radiation\"]\n",
        "\n",
        "# === 학습/테스트에서 공통으로 제거 ===\n",
        "df_train_clean = df_train.drop(columns=drop_cols_train, errors=\"ignore\")\n",
        "df_test_clean = df_test.drop(columns=drop_cols_test, errors=\"ignore\")\n",
        "\n",
        "print(\"Before:\", df_train.shape, df_test.shape)\n",
        "print(\"After :\", df_train_clean.shape, df_test_clean.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVxCkzRaluW3"
      },
      "outputs": [],
      "source": [
        "target_col = \"power_consumption\"\n",
        "X = df_train_clean.drop(columns=[target_col])\n",
        "y = df_train_clean[target_col].values.reshape(-1, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZR7QGHobnHXN"
      },
      "outputs": [],
      "source": [
        "X_test = df_test_clean.copy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def add_time_features(df):\n",
        "    # hour (0~23)\n",
        "    if \"hour\" in df.columns:\n",
        "        df[\"sin_hour\"] = np.sin(2 * np.pi * df[\"hour\"] / 24)\n",
        "        df[\"cos_hour\"] = np.cos(2 * np.pi * df[\"hour\"] / 24)\n",
        "\n",
        "    # day (1~31)\n",
        "    if \"day\" in df.columns:\n",
        "        df[\"sin_day\"] = np.sin(2 * np.pi * df[\"day\"] / 31)\n",
        "        df[\"cos_day\"] = np.cos(2 * np.pi * df[\"day\"] / 31)\n",
        "\n",
        "    # month (1~12)\n",
        "    if \"month\" in df.columns:\n",
        "        df[\"sin_month\"] = np.sin(2 * np.pi * df[\"month\"] / 12)\n",
        "        df[\"cos_month\"] = np.cos(2 * np.pi * df[\"month\"] / 12)\n",
        "\n",
        "    # day of week (0~6)\n",
        "    if \"dow\" in df.columns:\n",
        "        df[\"sin_dow\"] = np.sin(2 * np.pi * df[\"dow\"] / 7)\n",
        "        df[\"cos_dow\"] = np.cos(2 * np.pi * df[\"dow\"] / 7)\n",
        "\n",
        "    return df\n",
        "\n",
        "# === Train / Test 모두 적용 ===\n",
        "X = add_time_features(X)\n",
        "X_test = add_time_features(X_test)"
      ],
      "metadata": {
        "id": "ZxVPG-wnTyR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sO5YyZb9hnJ6"
      },
      "outputs": [],
      "source": [
        "# 타겟 분리\n",
        "target_col = \"power_consumption\"\n",
        "y = df_train[target_col]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miagBASYk_T8"
      },
      "outputs": [],
      "source": [
        "# 컬럼 구분\n",
        "categorical_features = [\"building_type\"]  # 원핫 인코딩 대상\n",
        "numeric_features = [col for col in X.columns if col not in categorical_features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYcozfSklK5U"
      },
      "outputs": [],
      "source": [
        "# 스케일링 대상 숫자형 피처 선정\n",
        "# (0/1 변수는 스케일링 불필요 → 제외)\n",
        "binary_like = [\"is_weekend\", \"has_pv\", \"has_ess\"]\n",
        "numeric_to_scale = [col for col in numeric_features if col not in binary_like]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKgp36WHlNs7"
      },
      "outputs": [],
      "source": [
        "#스케일러 정의\n",
        "numeric_transformer = RobustScaler()\n",
        "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
        "y_scaler = StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmTc3hb5lSts"
      },
      "outputs": [],
      "source": [
        "# ColumnTransformer 구성\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, numeric_to_scale),\n",
        "        (\"cat\", categorical_transformer, categorical_features)\n",
        "    ],\n",
        "    remainder=\"passthrough\"  # 스케일링 안 하는 피처는 그대로 둠\n",
        ")\n",
        "\n",
        "# 파이프라인\n",
        "X_pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYq5OMO7nAMw"
      },
      "outputs": [],
      "source": [
        "y = df_train[target_col].to_numpy().reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNkcoLltlcPO"
      },
      "outputs": [],
      "source": [
        "X_scaled = X_pipeline.fit_transform(X)\n",
        "X_test_scaled = X_pipeline.transform(X_test)\n",
        "y_scaled = y_scaler.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBtndlJVljOl",
        "outputId": "08b9682d-7495-40f0-c5ac-a8d6008de683"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.66792498],\n",
              "       [ 0.61291316],\n",
              "       [ 0.54415043],\n",
              "       ...,\n",
              "       [-0.08784707],\n",
              "       [-0.18458329],\n",
              "       [-0.10879466]])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "y_scaled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubw5ky_On6UL"
      },
      "source": [
        "#1D CNN, ResNet 모델링"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 시드 값\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# PyTorch 재현성 모드\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "e9Coilx6RS9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##데이터 변환\n",
        "X_tensor = torch.tensor(X_scaled_pca, dtype=torch.float32).unsqueeze(1)  # (n, 1, n_components)\n",
        "y_tensor = torch.tensor(y_scaled, dtype=torch.float32)\n",
        "\n",
        "X_test_tensor = torch.tensor(X_test_scaled_pca, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "print(\"Train X shape:\", X_tensor.shape)  # (n, 1, n_components)\n",
        "print(\"Train y shape:\", y_tensor.shape)  # (n, 1)\n",
        "print(\"Test X shape:\", X_test_tensor.shape)\n",
        "\n",
        "# Dataset/DataLoader\n",
        "dataset = TensorDataset(X_tensor, y_tensor)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=256, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrnWhsxvQtcy",
        "outputId": "41d4e012-ffd2-470f-af55-aca92622b6e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train X shape: torch.Size([203932, 1, 15])\n",
            "Train y shape: torch.Size([203932, 1])\n",
            "Test X shape: torch.Size([16800, 1, 15])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        padding = kernel_size // 2\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, stride=stride, padding=padding)\n",
        "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, stride=1, padding=padding)\n",
        "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
        "\n",
        "        # skip connection (채널/stride 다르면 projection 사용)\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if in_channels != out_channels or stride != 1:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
        "                nn.BatchNorm1d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        return torch.relu(out)"
      ],
      "metadata": {
        "id": "DWnuhBKpQ-Qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetRegressor(nn.Module):\n",
        "    def __init__(self, input_len):\n",
        "        super(ResNetRegressor, self).__init__()\n",
        "        self.layer1 = ResidualBlock(1, 32)\n",
        "        self.pool1 = nn.MaxPool1d(2)\n",
        "\n",
        "        self.layer2 = ResidualBlock(32, 64)\n",
        "        self.pool2 = nn.MaxPool1d(2)\n",
        "\n",
        "        conv_out_len = input_len // 4  # 두 번 pooling\n",
        "\n",
        "        self.fc1 = nn.Linear(64 * conv_out_len, 128)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc2 = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.layer1(x))\n",
        "        x = self.pool2(self.layer2(x))\n",
        "        x = x.view(x.size(0), -1)   # Flatten\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "v71wUZUQQ_6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = ResNetRegressor(input_len=X_scaled_pca.shape[1]).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    # --- Train ---\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item() * X_batch.size(0)\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "\n",
        "    # --- Validation ---\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            val_loss += loss.item() * X_batch.size(0)\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gopDZKQrRBum",
        "outputId": "26a91645-3009-4f12-de9c-6d2ad3d86925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Train Loss: 0.0492, Val Loss: 0.0183\n",
            "Epoch 2/50, Train Loss: 0.0273, Val Loss: 0.0131\n",
            "Epoch 3/50, Train Loss: 0.0242, Val Loss: 0.0129\n",
            "Epoch 4/50, Train Loss: 0.0234, Val Loss: 0.0140\n",
            "Epoch 5/50, Train Loss: 0.0220, Val Loss: 0.0109\n",
            "Epoch 6/50, Train Loss: 0.0214, Val Loss: 0.0099\n",
            "Epoch 7/50, Train Loss: 0.0207, Val Loss: 0.0181\n",
            "Epoch 8/50, Train Loss: 0.0203, Val Loss: 0.0109\n",
            "Epoch 9/50, Train Loss: 0.0202, Val Loss: 0.0130\n",
            "Epoch 10/50, Train Loss: 0.0196, Val Loss: 0.0098\n",
            "Epoch 11/50, Train Loss: 0.0189, Val Loss: 0.0091\n",
            "Epoch 12/50, Train Loss: 0.0189, Val Loss: 0.0107\n",
            "Epoch 13/50, Train Loss: 0.0187, Val Loss: 0.0094\n",
            "Epoch 14/50, Train Loss: 0.0181, Val Loss: 0.0085\n",
            "Epoch 15/50, Train Loss: 0.0181, Val Loss: 0.0084\n",
            "Epoch 16/50, Train Loss: 0.0181, Val Loss: 0.0115\n",
            "Epoch 17/50, Train Loss: 0.0178, Val Loss: 0.0086\n",
            "Epoch 18/50, Train Loss: 0.0174, Val Loss: 0.0100\n",
            "Epoch 19/50, Train Loss: 0.0172, Val Loss: 0.0114\n",
            "Epoch 20/50, Train Loss: 0.0174, Val Loss: 0.0122\n",
            "Epoch 21/50, Train Loss: 0.0171, Val Loss: 0.0103\n",
            "Epoch 22/50, Train Loss: 0.0165, Val Loss: 0.0071\n",
            "Epoch 23/50, Train Loss: 0.0166, Val Loss: 0.0075\n",
            "Epoch 24/50, Train Loss: 0.0166, Val Loss: 0.0101\n",
            "Epoch 25/50, Train Loss: 0.0162, Val Loss: 0.0068\n",
            "Epoch 26/50, Train Loss: 0.0159, Val Loss: 0.0097\n",
            "Epoch 27/50, Train Loss: 0.0161, Val Loss: 0.0072\n",
            "Epoch 28/50, Train Loss: 0.0160, Val Loss: 0.0066\n",
            "Epoch 29/50, Train Loss: 0.0157, Val Loss: 0.0068\n",
            "Epoch 30/50, Train Loss: 0.0158, Val Loss: 0.0066\n",
            "Epoch 31/50, Train Loss: 0.0157, Val Loss: 0.0078\n",
            "Epoch 32/50, Train Loss: 0.0152, Val Loss: 0.0063\n",
            "Epoch 33/50, Train Loss: 0.0154, Val Loss: 0.0088\n",
            "Epoch 34/50, Train Loss: 0.0153, Val Loss: 0.0067\n",
            "Epoch 35/50, Train Loss: 0.0150, Val Loss: 0.0061\n",
            "Epoch 36/50, Train Loss: 0.0151, Val Loss: 0.0073\n",
            "Epoch 37/50, Train Loss: 0.0151, Val Loss: 0.0067\n",
            "Epoch 38/50, Train Loss: 0.0148, Val Loss: 0.0062\n",
            "Epoch 39/50, Train Loss: 0.0146, Val Loss: 0.0082\n",
            "Epoch 40/50, Train Loss: 0.0147, Val Loss: 0.0068\n",
            "Epoch 41/50, Train Loss: 0.0146, Val Loss: 0.0060\n",
            "Epoch 42/50, Train Loss: 0.0147, Val Loss: 0.0060\n",
            "Epoch 43/50, Train Loss: 0.0145, Val Loss: 0.0094\n",
            "Epoch 44/50, Train Loss: 0.0145, Val Loss: 0.0076\n",
            "Epoch 45/50, Train Loss: 0.0144, Val Loss: 0.0059\n",
            "Epoch 46/50, Train Loss: 0.0143, Val Loss: 0.0074\n",
            "Epoch 47/50, Train Loss: 0.0144, Val Loss: 0.0103\n",
            "Epoch 48/50, Train Loss: 0.0143, Val Loss: 0.0065\n",
            "Epoch 49/50, Train Loss: 0.0142, Val Loss: 0.0066\n",
            "Epoch 50/50, Train Loss: 0.0140, Val Loss: 0.0063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_test_pred_scaled = model(X_test_tensor.to(device)).cpu().numpy()\n",
        "\n",
        "# y 복원\n",
        "y_test_pred = y_scaler.inverse_transform(y_test_pred_scaled)\n",
        "\n",
        "print(\"테스트 세트 예측 샘플:\", y_test_pred[:5].flatten())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nbk23vQ0RCq-",
        "outputId": "c8f8586a-0de2-4439-ca68-55e1096c0046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 세트 예측 샘플: [3666.0244 3448.2712 3429.3237 3421.4944 3339.2703]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub4 = pd.DataFrame(y_test_pred)"
      ],
      "metadata": {
        "id": "k3J0oQhnSM0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub4.to_csv('submission_04_jwp.csv')"
      ],
      "metadata": {
        "id": "PzvBVmoRSU2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBJGLR99s2zs"
      },
      "source": [
        "#Simple LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PO1QMiTBrQGB",
        "outputId": "3bd36326-c123-4e14-b034-d53cce6db58d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_tensor: torch.Size([203932, 1, 40])\n",
            "y_tensor: torch.Size([203932, 1])\n"
          ]
        }
      ],
      "source": [
        "# numpy → tensor 변환\n",
        "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y_scaled, dtype=torch.float32)\n",
        "\n",
        "# LSTM 입력 모양: (batch, seq_len, features)\n",
        "X_tensor = X_tensor.unsqueeze(1)  # (n, 1, feature_dim)\n",
        "\n",
        "print(\"X_tensor:\", X_tensor.shape)  # (샘플 수, 1, 피처 수)\n",
        "print(\"y_tensor:\", y_tensor.shape)  # (샘플 수, 1)\n",
        "\n",
        "# Dataset & DataLoader\n",
        "dataset = TensorDataset(X_tensor, y_tensor)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=256, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTyxCPzptQKz"
      },
      "outputs": [],
      "source": [
        "class LSTMRegressor(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=64, num_layers=2):\n",
        "        super(LSTMRegressor, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size=input_dim,\n",
        "                            hidden_size=hidden_dim,\n",
        "                            num_layers=num_layers,\n",
        "                            batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)  # 회귀 출력\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, seq_len=1, features)\n",
        "        out, _ = self.lstm(x)  # out: (batch, seq_len, hidden_dim)\n",
        "        out = out[:, -1, :]    # 마지막 시점 hidden state\n",
        "        out = self.fc(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GB3cpb1ZtTY2",
        "outputId": "eaf66872-e03c-4348-bc51-6ecf3545bff2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20, Train Loss: 0.0716, Val Loss: 0.0114\n",
            "Epoch 2/20, Train Loss: 0.0107, Val Loss: 0.0096\n",
            "Epoch 3/20, Train Loss: 0.0094, Val Loss: 0.0086\n",
            "Epoch 4/20, Train Loss: 0.0085, Val Loss: 0.0081\n",
            "Epoch 5/20, Train Loss: 0.0077, Val Loss: 0.0073\n",
            "Epoch 6/20, Train Loss: 0.0072, Val Loss: 0.0072\n",
            "Epoch 7/20, Train Loss: 0.0070, Val Loss: 0.0074\n",
            "Epoch 8/20, Train Loss: 0.0066, Val Loss: 0.0070\n",
            "Epoch 9/20, Train Loss: 0.0065, Val Loss: 0.0064\n",
            "Epoch 10/20, Train Loss: 0.0063, Val Loss: 0.0070\n",
            "Epoch 11/20, Train Loss: 0.0061, Val Loss: 0.0062\n",
            "Epoch 12/20, Train Loss: 0.0059, Val Loss: 0.0056\n",
            "Epoch 13/20, Train Loss: 0.0058, Val Loss: 0.0055\n",
            "Epoch 14/20, Train Loss: 0.0057, Val Loss: 0.0057\n",
            "Epoch 15/20, Train Loss: 0.0056, Val Loss: 0.0053\n",
            "Epoch 16/20, Train Loss: 0.0054, Val Loss: 0.0056\n",
            "Epoch 17/20, Train Loss: 0.0053, Val Loss: 0.0053\n",
            "Epoch 18/20, Train Loss: 0.0052, Val Loss: 0.0057\n",
            "Epoch 19/20, Train Loss: 0.0051, Val Loss: 0.0050\n",
            "Epoch 20/20, Train Loss: 0.0050, Val Loss: 0.0053\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = LSTMRegressor(input_dim=X_scaled.shape[1]).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    # --- Train ---\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item() * X_batch.size(0)\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "\n",
        "    # --- Validation ---\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            val_loss += loss.item() * X_batch.size(0)\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzZKmelrtV2P",
        "outputId": "b4cc5803-e18d-4a5e-941a-c40a62a48217"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "예측 복원 샘플: [ 565.231  3116.078   529.8936 1586.8206 1595.9186]\n",
            "실제값 샘플: [ 542.16   3223.08    608.16   1687.6799 1556.6399]\n"
          ]
        }
      ],
      "source": [
        "# 검증 세트 예측\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    X_val, y_val = next(iter(val_loader))\n",
        "    X_val, y_val = X_val.to(device), y_val.to(device)\n",
        "    y_pred_scaled = model(X_val).cpu().numpy()\n",
        "\n",
        "# y 복원\n",
        "y_pred = y_scaler.inverse_transform(y_pred_scaled)\n",
        "y_true = y_scaler.inverse_transform(y_val.cpu().numpy())\n",
        "\n",
        "print(\"예측 복원 샘플:\", y_pred[:5].flatten())\n",
        "print(\"실제값 샘플:\", y_true[:5].flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBwXe6x-tw18"
      },
      "outputs": [],
      "source": [
        "sub2 = pd.DataFrame(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEQb9jUnt7PQ"
      },
      "outputs": [],
      "source": [
        "sub2.to_csv('submission_02_jwp.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25ZA8MqLt_kJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TCN"
      ],
      "metadata": {
        "id": "jq2PlLcPUPLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_sliding_window(X, y, window_size=24):\n",
        "    \"\"\"\n",
        "    X: (n_samples, n_features)\n",
        "    y: (n_samples, 1)\n",
        "    window_size: 몇 시점씩 묶을지\n",
        "    \"\"\"\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - window_size):\n",
        "        Xs.append(X[i:i+window_size])   # 입력 시퀀스\n",
        "        ys.append(y[i+window_size])     # 다음 시점 target\n",
        "    return np.array(Xs), np.array(ys)"
      ],
      "metadata": {
        "id": "tfghUAA0Vztp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_size = 24  # 하루 단위\n",
        "X_seq, y_seq = create_sliding_window(X_scaled, y_scaled, window_size)\n",
        "\n",
        "# Torch tensor 변환 (TCN은 (batch, features, seq_len) 필요)\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "\n",
        "X_seq_torch = torch.tensor(X_seq, dtype=torch.float32).permute(0, 2, 1)  # (batch, features, seq_len)\n",
        "y_seq_torch = torch.tensor(y_seq, dtype=torch.float32)\n",
        "\n",
        "print(\"Train X shape:\", X_seq_torch.shape)\n",
        "print(\"Train y shape:\", y_seq_torch.shape)\n",
        "\n",
        "# Dataset/DataLoader\n",
        "dataset = TensorDataset(X_seq_torch, y_seq_torch)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=256, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNXFXIFvUQL6",
        "outputId": "89a34c2d-b2d9-4e28-8e55-dcd923602891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train X shape: torch.Size([203908, 44, 24])\n",
            "Train y shape: torch.Size([203908, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class TemporalBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, dilation=1, dropout=0.2):\n",
        "        super(TemporalBlock, self).__init__()\n",
        "        padding = (kernel_size - 1) * dilation // 2\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
        "                               padding=padding, dilation=dilation)\n",
        "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size,\n",
        "                               padding=padding, dilation=dilation)\n",
        "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        # skip connection\n",
        "        self.downsample = nn.Conv1d(in_channels, out_channels, kernel_size=1) if in_channels != out_channels else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.dropout1(self.relu1(self.bn1(self.conv1(x))))\n",
        "        out = self.dropout2(self.relu2(self.bn2(self.conv2(out))))\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return torch.relu(out + res)\n",
        "\n",
        "class TCNRegressor(nn.Module):\n",
        "    def __init__(self, input_channels, num_channels=[64, 128, 128], kernel_size=3, dropout=0.2):\n",
        "        super(TCNRegressor, self).__init__()\n",
        "        layers = []\n",
        "        for i in range(len(num_channels)):\n",
        "            in_ch = input_channels if i == 0 else num_channels[i-1]\n",
        "            out_ch = num_channels[i]\n",
        "            layers.append(TemporalBlock(in_ch, out_ch, kernel_size, dilation=2**i, dropout=dropout))\n",
        "        self.tcn = nn.Sequential(*layers)\n",
        "        self.fc = nn.Linear(num_channels[-1], 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.tcn(x)          # (batch, channels, seq_len)\n",
        "        out = out.mean(dim=2)      # Global average pooling\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "CNCiELrIUQ1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = TCNRegressor(input_channels=X_seq_torch.shape[1]).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    # --- Train ---\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item() * X_batch.size(0)\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "\n",
        "    # --- Validation ---\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            val_loss += loss.item() * X_batch.size(0)\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5S-ORQaYUUwn",
        "outputId": "ba76b420-7f2e-46e0-d16f-2ad8623080af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Train Loss: 0.0493, Val Loss: 0.0201\n",
            "Epoch 2/20, Train Loss: 0.0219, Val Loss: 0.0143\n",
            "Epoch 3/20, Train Loss: 0.0168, Val Loss: 0.0108\n",
            "Epoch 4/20, Train Loss: 0.0142, Val Loss: 0.0104\n",
            "Epoch 5/20, Train Loss: 0.0132, Val Loss: 0.0100\n",
            "Epoch 6/20, Train Loss: 0.0121, Val Loss: 0.0092\n",
            "Epoch 7/20, Train Loss: 0.0113, Val Loss: 0.0093\n",
            "Epoch 8/20, Train Loss: 0.0104, Val Loss: 0.0084\n",
            "Epoch 9/20, Train Loss: 0.0096, Val Loss: 0.0084\n",
            "Epoch 10/20, Train Loss: 0.0092, Val Loss: 0.0099\n",
            "Epoch 11/20, Train Loss: 0.0090, Val Loss: 0.0066\n",
            "Epoch 12/20, Train Loss: 0.0084, Val Loss: 0.0077\n",
            "Epoch 13/20, Train Loss: 0.0082, Val Loss: 0.0065\n",
            "Epoch 14/20, Train Loss: 0.0078, Val Loss: 0.0060\n",
            "Epoch 15/20, Train Loss: 0.0072, Val Loss: 0.0066\n",
            "Epoch 16/20, Train Loss: 0.0071, Val Loss: 0.0061\n",
            "Epoch 17/20, Train Loss: 0.0068, Val Loss: 0.0066\n",
            "Epoch 18/20, Train Loss: 0.0064, Val Loss: 0.0056\n",
            "Epoch 19/20, Train Loss: 0.0064, Val Loss: 0.0059\n",
            "Epoch 20/20, Train Loss: 0.0061, Val Loss: 0.0062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test 데이터에도 동일하게 sliding window 적용\n",
        "X_test_seq = []\n",
        "for i in range(len(X_test_scaled) - window_size):\n",
        "    X_test_seq.append(X_test_scaled[i:i+window_size])\n",
        "X_test_seq = np.array(X_test_seq)\n",
        "\n",
        "X_test_seq_torch = torch.tensor(X_test_seq, dtype=torch.float32).permute(0, 2, 1).to(device)\n",
        "\n",
        "# 예측\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_test_pred_scaled = model(X_test_seq_torch).cpu().numpy()\n",
        "\n",
        "# 스케일 복원\n",
        "y_test_pred = y_scaler.inverse_transform(y_test_pred_scaled)\n",
        "\n",
        "print(\"테스트 세트 예측 샘플:\", y_test_pred[:5].flatten())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6ZJlbJeUYgd",
        "outputId": "3613f92b-2814-4986-b21a-d0ede4310fd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 세트 예측 샘플: [4316.558  4127.894  3973.6975 3808.317  3701.1484]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub6 = pd.DataFrame(y_test_pred)"
      ],
      "metadata": {
        "id": "dYqShfs5Ubj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub6.to_csv('submission_06_jwp.csv')"
      ],
      "metadata": {
        "id": "SwkfvPiBVLQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hiyI8TERVNo2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Ubw5ky_On6UL"
      ],
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}